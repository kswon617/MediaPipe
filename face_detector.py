import cv2
import mediapipe as mp

# MediaPipe ì´ˆê¸°í™”
mp_face_mesh = mp.solutions.face_mesh

# ì£¼ìš” ëœë“œë§ˆí¬ ì¸ë±ìŠ¤ (ëˆˆ, ì½”, ì…, ê·€)
LANDMARK_IDS = {
    "left_eye": 468,
    "right_eye": 473,
    "nose_tip": 1,
    "upper_lip": 13,
    "lower_lip": 14,
    "left_ear": 234,
    "right_ear": 454
}

face_mesh = mp_face_mesh.FaceMesh(
    max_num_faces=1,
    refine_landmarks=True,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)

cap = cv2.VideoCapture("face.mp4")
if not cap.isOpened():
    print("âš ï¸ ë™ì˜ìƒ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

while cap.isOpened():
    success, image = cap.read()
    if not success:
        break

    image = cv2.flip(image, 1)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    results = face_mesh.process(image_rgb)

    if results.multi_face_landmarks:
        for face_landmarks in results.multi_face_landmarks:
            h, w, _ = image.shape

            # ëª¨ë“  ëœë“œë§ˆí¬ ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸ ì–»ê¸°
            landmark_points = [(int(lm.x * w), int(lm.y * h)) for lm in face_landmarks.landmark]

            # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚° (x, y, w, h)
            x_vals = [p[0] for p in landmark_points]
            y_vals = [p[1] for p in landmark_points]
            x_min, x_max = min(x_vals), max(x_vals)
            y_min, y_max = min(y_vals), max(y_vals)

            # ì–¼êµ´ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (í°ìƒ‰)
            cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (255, 255, 255), 2)

            # ì£¼ìš” í¬ì¸íŠ¸ ë¹¨ê°„ ì  ì°ê¸°
            for idx in LANDMARK_IDS.values():
                x, y = landmark_points[idx]
                cv2.circle(image, (x, y), 4, (0, 0, 255), -1)

    cv2.imshow("ğŸ‘¤ ì–¼êµ´ ì‚¬ê°í˜• + ì£¼ìš” íŠ¹ì§•ì ", image)
    if cv2.waitKey(5) & 0xFF == 27:
        break

cap.release()
cv2.destroyAllWindows()
